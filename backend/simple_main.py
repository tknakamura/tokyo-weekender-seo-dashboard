"""
Simple Tokyo Weekender SEO Analysis Dashboard - FastAPI Backend
This version works without database dependencies for immediate deployment
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pathlib import Path
import json
import pandas as pd
from typing import Dict, List, Optional
import uvicorn

app = FastAPI(
    title="Tokyo Weekender SEO Dashboard API",
    description="Tokyo Weekenderã®Organic Growthåˆ†æžAPI",
    version="1.0.0"
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000", 
        "http://localhost:5173",
        "https://tokyo-weekender-seo-dashboard.onrender.com"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
DATA_PATH = Path("data/processed")
RAW_DATA_PATH = Path("data/raw")

@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®å‡¦ç†"""
    print("ðŸš€ Tokyo Weekender Backend starting up...")
    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    DATA_PATH.mkdir(parents=True, exist_ok=True)
    RAW_DATA_PATH.mkdir(parents=True, exist_ok=True)
    print("âœ… Data directories created")

@app.get("/")
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "Tokyo Weekender SEO Analysis Dashboard API",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/api/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "healthy", "message": "Tokyo Weekender Backend is running"}

@app.get("/api/test")
async def test_endpoint():
    """ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "Backend is working!",
        "timestamp": "2025-09-27T01:49:00Z",
        "version": "1.0.0"
    }

def find_csv_file():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    csv_files = [
        RAW_DATA_PATH / "www.tokyoweekender.com-organic-keywords-sub_2025-09-26_06-49-18.csv",
        Path("csv/www.tokyoweekender.com-organic-keywords-sub_2025-09-26_06-49-18.csv"),
        Path("data/raw/www.tokyoweekender.com-organic-keywords-sub_2025-09-26_06-49-18.csv"),
        Path("www.tokyoweekender.com-organic-keywords-sub_2025-09-26_06-49-18.csv")
    ]
    
    for file_path in csv_files:
        if file_path.exists():
            print(f"âœ… Found CSV file: {file_path}")
            return file_path
    
    print("âŒ No CSV file found")
    return None

@app.get("/api/keywords/search")
async def search_keywords(
    min_volume: int = 100,
    max_position: int = 50,
    intent: str = "",
    location: str = "",
    limit: int = 100
):
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ä»˜ãï¼‰"""
    try:
        csv_file = find_csv_file()
        if not csv_file:
            raise HTTPException(status_code=404, detail="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        df = pd.read_csv(csv_file)
        print(f"ðŸ“Š Loaded {len(df)} keywords from CSV")
        
        # Apply filters
        if min_volume > 0:
            df = df[df['Volume'] >= min_volume]
        
        if max_position > 0:
            df = df[df['Current position'] <= max_position]
        
        if intent:
            if intent in df.columns:
                df = df[df[intent] == True]
        
        if location:
            df = df[df['Location'] == location]
        
        # Sort and limit
        df = df.sort_values(['Organic traffic', 'Current position'], ascending=[False, True])
        df = df.head(limit)
        
        result = df.to_dict('records')
        print(f"ðŸ“ˆ Returning {len(result)} filtered keywords")
        return result
        
    except Exception as e:
        print(f"âŒ Search error: {e}")
        raise HTTPException(status_code=500, detail=f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã«å¤±æ•—: {str(e)}")

@app.get("/api/keywords/locations")
async def get_available_locations():
    """åˆ©ç”¨å¯èƒ½ãªå›½ãƒ»åœ°åŸŸãƒªã‚¹ãƒˆã®å–å¾—"""
    try:
        csv_file = find_csv_file()
        if not csv_file:
            raise HTTPException(status_code=404, detail="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        df = pd.read_csv(csv_file)
        print(f"ðŸ“Š Loaded {len(df)} keywords for location analysis")
        
        # Get unique locations with counts
        location_counts = df['Location'].value_counts().head(10)
        locations = []
        
        for location, count in location_counts.items():
            if pd.notna(location) and location != '':
                total_traffic = df[df['Location'] == location]['Organic traffic'].sum()
                locations.append({
                    'location': location,
                    'keyword_count': int(count),
                    'total_traffic': int(total_traffic) if pd.notna(total_traffic) else 0
                })
        
        print(f"ðŸŒ Returning {len(locations)} locations")
        return locations
        
    except Exception as e:
        print(f"âŒ Locations error: {e}")
        raise HTTPException(status_code=500, detail=f"å›½ãƒ»åœ°åŸŸãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
